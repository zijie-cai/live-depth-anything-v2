{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "xFormers not available\n",
      "xFormers not available\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1WA67pX-IhSxpj9yXQbeHOVjYfaVynEmF\n",
      "From (redirected): https://drive.google.com/uc?id=1WA67pX-IhSxpj9yXQbeHOVjYfaVynEmF&confirm=t&uuid=d4a8f453-59ed-40c2-9541-33b5a54d489a\n",
      "To: /Users/zai28/Desktop/live-depth/checkpoints/depth_anything_v2_vits.pth\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99.2M/99.2M [00:03<00:00, 32.5MB/s]\n",
      "/var/folders/x3/01wh1hd93vs_23l7lk3kcnsh0000gn/T/ipykernel_71658/2591490032.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('depth_anything_v2_vits.pth', map_location=DEVICE))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2fd3010201b4513829cee772c4a2b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n    <style>\\n        .fa-video-camera {\\n            font-size: 30px !important;\\â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import threading\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from depth_anything_v2.dpt import DepthAnythingV2\n",
    "import gdown\n",
 
    "# Global flag to control the webcam stream\n",
    "is_streaming = False\n",
    "stream_thread = None\n",
    "display_lock = threading.Lock()  # Lock to sync the display updates\n",
    "\n",
    "# Set up the depth estimation model\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_configs = {\n",
    "    'vits': {'encoder': 'vits', 'features': 64, 'out_channels': [48, 96, 192, 384]},\n",
    "    'vitb': {'encoder': 'vitb', 'features': 128, 'out_channels': [96, 192, 384, 768]},\n",
    "    'vitl': {'encoder': 'vitl', 'features': 256, 'out_channels': [256, 512, 1024, 1024]},\n",
    "    'vitg': {'encoder': 'vitg', 'features': 384, 'out_channels': [1536, 1536, 1536, 1536]}\n",
    "}\n",
    "encoder = 'vits'  # You can choose between 'vits', 'vitb', 'vitl', and 'vitg'\n",
    "model = DepthAnythingV2(**model_configs[encoder])\n",
    "model.load_state_dict(torch.load('/home/jovyan/depth_anything_v2_vits.pth', map_location=DEVICE))\n",
    "model = model.to(DEVICE).eval()\n",
    "\n",
    "# Function to start/stop webcam feed\n",
    "def toggle_webcam(button):\n",
    "    global is_streaming, stream_thread\n",
    "\n",
    "    if is_streaming:\n",
    "        # Stop the stream\n",
    "        is_streaming = False\n",
    "        button.icon = 'video-camera'  # Change icon back to camera\n",
    "        button.style.button_color = \"#FFFFFF\"\n",
    "        style.value = \"\"\"\n",
    "        <style>\n",
    "            .fa-video-camera {\n",
    "                font-size: 30px !important;\n",
    "                color: black !important;\n",
    "            }\n",
    "        </style>\n",
    "        \"\"\"\n",
    "        if stream_thread is not None:\n",
    "            stream_thread.join()  # Ensure the thread finishes properly\n",
    "        gray_out_camera_view()\n",
    "        gray_out_depth_view()\n",
    "    else:\n",
    "        # Start the stream\n",
    "        is_streaming = True\n",
    "        button.icon = 'video-camera'\n",
    "        button.style.button_color = \"#FFFFFF\"\n",
    "        style.value = \"\"\"\n",
    "        <style>\n",
    "            .fa-video-camera {\n",
    "                font-size: 30px !important;\n",
    "                color: red !important;\n",
    "            }\n",
    "        </style>\n",
    "        \"\"\"\n",
    "        # Start webcam and depth estimation in a single thread\n",
    "        stream_thread = threading.Thread(target=start_webcam_and_depth)\n",
    "        stream_thread.start()\n",
    "\n",
    "# Function to capture and display the webcam feed and depth map\n",
    "def start_webcam_and_depth():\n",
    "    cap = cv2.VideoCapture(0)  # Use default camera\n",
    "    cap.set(cv2.CAP_PROP_FPS, 30)  # Attempt to set 30 FPS\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video stream.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        while is_streaming:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to capture image\")\n",
    "                break\n",
    "\n",
    "            # Resize the frame to a smaller resolution to increase FPS\n",
    "            frame_resized = cv2.resize(frame, (320, 240))\n",
    "\n",
    "            # Convert the frame from BGR (OpenCV format) to RGB\n",
    "            rgb_frame = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Estimate depth using the model\n",
    "            with torch.no_grad():\n",
    "                depth_map = model.infer_image(frame_resized)\n",
    "\n",
    "            # Convert the depth map to a grayscale image\n",
    "            depth_colored = cv2.applyColorMap(cv2.normalize(depth_map, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8), cv2.COLORMAP_JET)\n",
    "\n",
    "            # Synchronize the display updates\n",
    "            with display_lock:\n",
    "                # Convert the frame to a PIL image and display it in the camera view widget\n",
    "                pil_img = Image.fromarray(rgb_frame)\n",
    "                with BytesIO() as f:\n",
    "                    pil_img.save(f, 'jpeg')\n",
    "                    cam_output.value = f.getvalue()\n",
    "\n",
    "                # Convert the depth map to a PIL image and display it in the depth view widget\n",
    "                depth_pil_img = Image.fromarray(cv2.cvtColor(depth_colored, cv2.COLOR_BGR2RGB))\n",
    "                with BytesIO() as f:\n",
    "                    depth_pil_img.save(f, 'jpeg')\n",
    "                    depth_output.value = f.getvalue()\n",
    "\n",
    "            # Limit the FPS to 30 by sleeping\n",
    "            time.sleep(1/30)\n",
    "\n",
    "    finally:\n",
    "        cap.release()  # Ensure the camera is released\n",
    "        cv2.destroyAllWindows()\n",
    "        gray_out_camera_view()\n",
    "        gray_out_depth_view()\n",
    "\n",
    "# Function to gray out the camera view area when the webcam is stopped\n",
    "def gray_out_camera_view():\n",
    "    gray_image = Image.new(\"RGB\", (320, 240), color=(128, 128, 128))\n",
    "    with BytesIO() as f:\n",
    "        gray_image.save(f, 'jpeg')\n",
    "        cam_output.value = f.getvalue()\n",
    "\n",
    "# Function to gray out the depth map view area when the depth map is not available\n",
    "def gray_out_depth_view():\n",
    "    gray_image = Image.new(\"RGB\", (320, 240), color=(128, 128, 128))\n",
    "    with BytesIO() as f:\n",
    "        gray_image.save(f, 'jpeg')\n",
    "        depth_output.value = f.getvalue()\n",
    "\n",
    "# Create the main widgets for the interface\n",
    "title = widgets.HTML(value=\"<h1 style='text-align:center; margin-bottom: 10px;'>ðŸ“¸ Live Cam Depth Anything V2</h1>\")\n",
    "camera_label = widgets.HTML(value=\"<h3 style='text-align:left; margin-top: 0;'>Camera View:</h3>\")\n",
    "cam_output = widgets.Image(layout={'height': '240px', 'width': '320px'})  # 320x240 camera live view\n",
    "depth_label = widgets.HTML(value=\"<h3 style='text-align:left;'>Depth Prediction:</h3>\")\n",
    "depth_output = widgets.Image(layout={'height': '240px', 'width': '320px'})  # 320x240 depth map\n",
    "\n",
    "# Initially gray out the camera and depth views\n",
    "gray_out_camera_view()\n",
    "gray_out_depth_view()\n",
    "\n",
    "# Create a circular toggle button with a larger icon using custom HTML\n",
    "toggle_button = widgets.Button(\n",
    "    description='',  # No text\n",
    "    icon='video-camera',  # Font Awesome camera icon\n",
    "    layout=widgets.Layout(width='60px', height='60px', margin='10px 0 0 0'),\n",
    ")\n",
    "toggle_button.style.button_color = '#FFFFFF'\n",
    "style = widgets.HTML(value=\"\"\"\n",
    "    <style>\n",
    "        .fa-video-camera {\n",
    "            font-size: 30px !important;\n",
    "        }\n",
    "    </style>\n",
    "\"\"\")\n",
    "toggle_button.on_click(toggle_webcam)\n",
    "\n",
    "# Organize the layout in a vertical box (VBox) and center the content\n",
    "ui = widgets.VBox([\n",
    "    style,\n",
    "    title,\n",
    "    camera_label, \n",
    "    cam_output,\n",
    "    depth_label, \n",
    "    depth_output,\n",
    "    toggle_button\n",
    "], layout=widgets.Layout(align_items='center'))\n",
    "\n",
    "# Display the organized UI with the CSS style included\n",
    "display(ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depthanything",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
